22/01/30 23:05:39 INFO SparkContext: Running Spark version 3.1.2
22/01/30 23:05:39 INFO ResourceUtils: ==============================================================
22/01/30 23:05:39 INFO ResourceUtils: No custom resources configured for spark.driver.
22/01/30 23:05:39 INFO ResourceUtils: ==============================================================
22/01/30 23:05:39 INFO SparkContext: Submitted application: Python Spark SQL basic example
22/01/30 23:05:39 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/01/30 23:05:39 INFO ResourceProfile: Limiting resource is cpu
22/01/30 23:05:39 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/01/30 23:05:39 INFO SecurityManager: Changing view acls to: inhwa
22/01/30 23:05:39 INFO SecurityManager: Changing modify acls to: inhwa
22/01/30 23:05:39 INFO SecurityManager: Changing view acls groups to: 
22/01/30 23:05:39 INFO SecurityManager: Changing modify acls groups to: 
22/01/30 23:05:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(inhwa); groups with view permissions: Set(); users  with modify permissions: Set(inhwa); groups with modify permissions: Set()
22/01/30 23:05:47 INFO Utils: Successfully started service 'sparkDriver' on port 65318.
22/01/30 23:05:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/01/30 23:05:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/01/30 23:05:47 INFO DiskBlockManager: Created local directory at C:\Users\inhwa\AppData\Local\Temp\blockmgr-be76eae4-7eb7-40e5-94d9-840c895f555f
22/01/30 23:05:47 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/01/30 23:05:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/01/30 23:05:47 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://DESKTOP-O74KG4H:4040
22/01/30 23:05:48 INFO Executor: Starting executor ID driver on host DESKTOP-O74KG4H
22/01/30 23:05:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65333.
22/01/30 23:05:48 INFO NettyBlockTransferService: Server created on DESKTOP-O74KG4H:65333
22/01/30 23:05:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/01/30 23:05:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, DESKTOP-O74KG4H, 65333, None)
22/01/30 23:05:48 INFO BlockManagerMasterEndpoint: Registering block manager DESKTOP-O74KG4H:65333 with 366.3 MiB RAM, BlockManagerId(driver, DESKTOP-O74KG4H, 65333, None)
22/01/30 23:05:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, DESKTOP-O74KG4H, 65333, None)
22/01/30 23:05:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, DESKTOP-O74KG4H, 65333, None)
22/01/30 23:05:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/workspace/data-engineering/Step4_spark/spark-warehouse').
22/01/30 23:05:49 INFO SharedState: Warehouse path is 'file:/D:/workspace/data-engineering/Step4_spark/spark-warehouse'.
22/01/30 23:05:51 INFO SparkUI: Stopped Spark web UI at http://DESKTOP-O74KG4H:4040
22/01/30 23:05:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
22/01/30 23:05:51 INFO MemoryStore: MemoryStore cleared
22/01/30 23:05:51 INFO BlockManager: BlockManager stopped
22/01/30 23:05:51 INFO BlockManagerMaster: BlockManagerMaster stopped
22/01/30 23:05:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
22/01/30 23:05:51 INFO SparkContext: Successfully stopped SparkContext
